{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f13a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "Name: data 1, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_list = [\n",
    "    ['value', 1],\n",
    "    ['another value', 2],\n",
    "    ['third value', 3]\n",
    "]\n",
    "\n",
    "_columns = ['data 1', 'data2']\n",
    "\n",
    "df = pd.DataFrame(data = test_list, columns = _columns)\n",
    "\n",
    "print(df['data 1'] == 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1745d2",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 2.1 - Solucionar problemas con archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31db83ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  letters  colors  decimals\n",
      "0       a  yellow       1.2\n",
      "1       b     red       1.3\n",
      "2       c    cyan       1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\Roberto Carlos\\\\source\\\\repos\\\\TripleTen_Data Science\\\\data_files\\\\letters_colors_decimals.csv',\n",
    "                   sep = '$',\n",
    "                   decimal = 'a')\n",
    "\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44adb77",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 2.2 - Cómo leer archivos Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fea4449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviews':             id reviewer_id  product_id  review\n",
      "0   2546305677    cG441617  5003186430       3\n",
      "1   2603422798    cH443811  7130698135       1\n",
      "2   2598103631    bF100137  4023404310       4\n",
      "3   2632674394    cF786880  7130698135       4\n",
      "4   2594782880    aF649317  5003186430       5\n",
      "..         ...         ...         ...     ...\n",
      "95  2546555594    cG613933  8847800628       4\n",
      "96  2622420412    bH854007  4023404310       1\n",
      "97  2611054167    cG907457  5003186430       1\n",
      "98  2584379264    cG907457  9741979309       4\n",
      "99  2569437101    aF484180  2203505344       3\n",
      "\n",
      "[100 rows x 4 columns], 'reviewers':           id date_joined  zipcode\n",
      "0   aF195825  2012-06-21    91914\n",
      "1   aF249047  2019-03-26    91915\n",
      "2   aF362092  2012-01-05    91941\n",
      "3   aF484180  2019-06-11    91941\n",
      "4   aF539111  2011-03-04    92003\n",
      "..       ...         ...      ...\n",
      "75  cH723093  2016-08-18    92083\n",
      "76  cH743487  2018-02-06    92083\n",
      "77  cH777358  2014-01-22    92083\n",
      "78  cH851609  2011-04-22    92083\n",
      "79  cH988589  2014-02-21    92083\n",
      "\n",
      "[80 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\"E:\\\\datasets\\\\product_reviews.xlsx\", sheet_name = ['reviews', 'reviewers'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e3d39",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 2.3 - Observación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a65e0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driverId   driverRef number code  forename     surname         dob  \\\n",
      "0         1    hamilton     44  HAM     Lewis    Hamilton  1985-01-07   \n",
      "1         2    heidfeld     \\N  HEI      Nick    Heidfeld  1977-05-10   \n",
      "2         3     rosberg      6  ROS      Nico     Rosberg  1985-06-27   \n",
      "3         4      alonso     14  ALO  Fernando      Alonso  1981-07-29   \n",
      "4         5  kovalainen     \\N  KOV    Heikki  Kovalainen  1981-10-19   \n",
      "\n",
      "  nationality                                             url  \n",
      "0     British     http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
      "1      German      http://en.wikipedia.org/wiki/Nick_Heidfeld  \n",
      "2      German       http://en.wikipedia.org/wiki/Nico_Rosberg  \n",
      "3     Spanish    http://en.wikipedia.org/wiki/Fernando_Alonso  \n",
      "4     Finnish  http://en.wikipedia.org/wiki/Heikki_Kovalainen  \n",
      "\n",
      "     driverId   driverRef number code forename     surname         dob  \\\n",
      "302       303  vonlanthen     \\N   \\N       Jo  Vonlanthen  1942-05-31   \n",
      "584       584     kessler     \\N   \\N    Bruce     Kessler  1936-03-23   \n",
      "15         16       sutil     99  SUT   Adrian       Sutil  1983-01-11   \n",
      "\n",
      "    nationality                                         url  \n",
      "302       Swiss  http://en.wikipedia.org/wiki/Jo_Vonlanthen  \n",
      "584    American  http://en.wikipedia.org/wiki/Bruce_Kessler  \n",
      "15       German   http://en.wikipedia.org/wiki/Adrian_Sutil  \n",
      "\n",
      "(859, 9)\n",
      "\n",
      "driverId        int64\n",
      "driverRef      object\n",
      "number         object\n",
      "code           object\n",
      "forename       object\n",
      "surname        object\n",
      "dob            object\n",
      "nationality    object\n",
      "url            object\n",
      "dtype: object\n",
      "\n",
      "Index(['driverId', 'driverRef', 'number', 'code', 'forename', 'surname', 'dob',\n",
      "       'nationality', 'url'],\n",
      "      dtype='object')\n",
      "\n",
      "driverId       0\n",
      "driverRef      0\n",
      "number         0\n",
      "code           0\n",
      "forename       0\n",
      "surname        0\n",
      "dob            0\n",
      "nationality    0\n",
      "url            0\n",
      "dtype: int64\n",
      "\n",
      "driverId       859\n",
      "driverRef      859\n",
      "number         859\n",
      "code           859\n",
      "forename       859\n",
      "surname        859\n",
      "dob            859\n",
      "nationality    859\n",
      "url            859\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 859 entries, 0 to 858\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   driverId     859 non-null    int64 \n",
      " 1   driverRef    859 non-null    object\n",
      " 2   number       859 non-null    object\n",
      " 3   code         859 non-null    object\n",
      " 4   forename     859 non-null    object\n",
      " 5   surname      859 non-null    object\n",
      " 6   dob          859 non-null    object\n",
      " 7   nationality  859 non-null    object\n",
      " 8   url          859 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 60.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"E:\\\\datasets\\\\Driver_Details.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "sample = df.sample(3)\n",
    "print(sample)\n",
    "print()\n",
    "\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "print(df.dtypes)\n",
    "print()\n",
    "\n",
    "print(df.columns)\n",
    "print()\n",
    "\n",
    "print(df.isnull().sum())\n",
    "print()\n",
    "\n",
    "print(df.notnull().sum())\n",
    "print()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c012771",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 2.4 Descripciones numéricas y describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66bb0e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         driverId\n",
      "count  859.000000\n",
      "mean   430.059371\n",
      "std    248.213115\n",
      "min      1.000000\n",
      "25%    215.500000\n",
      "50%    430.000000\n",
      "75%    644.500000\n",
      "max    860.000000\n",
      "\n",
      "       driverRef number code forename surname         dob nationality  \\\n",
      "count        859    859  859      859     859         859         859   \n",
      "unique       859     47   97      478     800         841          42   \n",
      "top      bearman     \\N   \\N     John  Taylor  1942-05-27     British   \n",
      "freq           1    802  757       14       5           2         166   \n",
      "\n",
      "                                                url  \n",
      "count                                           859  \n",
      "unique                                          859  \n",
      "top     http://en.wikipedia.org/wiki/Oliver_Bearman  \n",
      "freq                                              1  \n",
      "\n",
      "          driverId driverRef number code forename surname         dob  \\\n",
      "count   859.000000       859    859  859      859     859         859   \n",
      "unique         NaN       859     47   97      478     800         841   \n",
      "top            NaN   bearman     \\N   \\N     John  Taylor  1942-05-27   \n",
      "freq           NaN         1    802  757       14       5           2   \n",
      "mean    430.059371       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "std     248.213115       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "min       1.000000       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "25%     215.500000       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "50%     430.000000       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "75%     644.500000       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "max     860.000000       NaN    NaN  NaN      NaN     NaN         NaN   \n",
      "\n",
      "       nationality                                          url  \n",
      "count          859                                          859  \n",
      "unique          42                                          859  \n",
      "top        British  http://en.wikipedia.org/wiki/Oliver_Bearman  \n",
      "freq           166                                            1  \n",
      "mean           NaN                                          NaN  \n",
      "std            NaN                                          NaN  \n",
      "min            NaN                                          NaN  \n",
      "25%            NaN                                          NaN  \n",
      "50%            NaN                                          NaN  \n",
      "75%            NaN                                          NaN  \n",
      "max            NaN                                          NaN  \n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"E:\\\\datasets\\\\Driver_Details.csv\")\n",
    "\n",
    "print(data.describe())\n",
    "print()\n",
    "\n",
    "print(data.describe(include = 'object'))\n",
    "print()\n",
    "\n",
    "print(data.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22f2cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count         859\n",
      "unique         42\n",
      "top       British\n",
      "freq          166\n",
      "Name: nationality, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"E:\\\\datasets\\\\Driver_Details.csv\")\n",
    "\n",
    "print(data[\"nationality\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f53f2",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.1 - Problemas con los datos: entra basura, sale basura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de09949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin actividad practica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec4f46",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.2 - Renombrar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2e43fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old columns names:\n",
      "Index(['  user_id', 'total play', 'Artist', 'genre', 'track'], dtype='object')\n",
      "\n",
      "New columns names:\n",
      "Index(['user_id', 'total_play', 'artist', 'genre', 'track'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('E:\\\\datasets\\\\music_log_raw.csv')\n",
    "\n",
    "print('Old columns names:')\n",
    "print(df.columns)\n",
    "print()\n",
    "\n",
    "new_col_names = []\n",
    "\n",
    "for old_name in df.columns:\n",
    "    new_name = old_name.strip().lower().replace(' ','_')\n",
    "    new_col_names.append(new_name)\n",
    "\n",
    "df.columns = new_col_names\n",
    "\n",
    "print('New columns names:')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f65689",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.3 - Procesar valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76eebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id        0\n",
      "total play     564\n",
      "Artist        8317\n",
      "genre         3302\n",
      "track         3159\n",
      "dtype: int64\n",
      "\n",
      "  user_id       0\n",
      "total play    564\n",
      "Artist          0\n",
      "genre           0\n",
      "track           0\n",
      "dtype: int64\n",
      "\n",
      "  user_id     0\n",
      "total play    0\n",
      "Artist        0\n",
      "genre         0\n",
      "track         0\n",
      "dtype: int64\n",
      "\n",
      "  user_id     0\n",
      "total play    0\n",
      "Artist        0\n",
      "genre         0\n",
      "track         0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Carlos\\AppData\\Local\\Temp\\ipykernel_28992\\3303790339.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('no_info', inplace = True)\n",
      "C:\\Users\\Roberto Carlos\\AppData\\Local\\Temp\\ipykernel_28992\\3303790339.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['total play'].fillna(0, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#Ejercicios guiados\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('E:\\\\datasets\\\\music_log_raw.csv')\n",
    "\n",
    "mis_val = df.isna().sum()\n",
    "print(mis_val)\n",
    "print()\n",
    "\n",
    "columns_to_replace = ['genre', 'Artist', 'track']\n",
    "\n",
    "for col in columns_to_replace:\n",
    "\tdf[col].fillna('no_info', inplace = True)\n",
    "\t\n",
    "mis_val = df.isna().sum()\n",
    "print(mis_val)\n",
    "print()\n",
    "\n",
    "df['total play'].fillna(0, inplace = True)\n",
    "mis_val = df.isna().sum()\n",
    "print(mis_val)\n",
    "print()\n",
    "\n",
    "df.dropna(subset = ['total play'], inplace = True)\n",
    "mis_val = df.isna().sum()\n",
    "print(mis_val)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b890ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well_id            0\n",
      "production_date    0\n",
      "oil_volume         3\n",
      "gas_volume         0\n",
      "region             0\n",
      "status             2\n",
      "dtype: int64\n",
      "\n",
      "well_id            0\n",
      "production_date    0\n",
      "oil_volume         0\n",
      "gas_volume         0\n",
      "region             0\n",
      "status             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'well_id': ['W1', 'W2', 'W3', 'W4', 'W5', 'W6'],\n",
    "    'production_date': ['2024-01-01', '2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-02'],\n",
    "    'oil_volume': [100, None, 200, 300, None, None],\n",
    "    'gas_volume': [1000, 800, 950, 1100, 850, 900],\n",
    "    'region': ['North', 'North', 'South', 'South', 'West', 'West'],\n",
    "    'status': ['active', None, 'active', 'inactive', None, 'active']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.isna().sum())\n",
    "print()\n",
    "\n",
    "#df['oil_volume'].fillna(0, inplace = True)\n",
    "#df['status'].fillna('unknown', inplace = True)\n",
    "\n",
    "df['oil_volume'] = df['oil_volume'].fillna(0)\n",
    "df['status'] = df['status'].fillna('unknown')\n",
    "print(df.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'well_id': ['W1', 'W2', 'W3', 'W4', 'W5', 'W6'],\n",
    "    'production_date': ['2024-01-01', '2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-02'],\n",
    "    'oil_volume': [100, None, 200, 300, None, None],\n",
    "    'gas_volume': [1000, 800, 950, 1100, 850, 900],\n",
    "    'region': ['North', 'North', 'South', 'South', 'West', 'West'],\n",
    "    'status': ['active', None, 'active', 'inactive', None, 'active']\n",
    "}\n",
    "\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "print(\"Valores ausentes antes de la eliminación:\")\n",
    "print(df.isna().sum())\n",
    "print()\n",
    "print(df['oil_volume'].isna().sum())\n",
    "print()\n",
    "\n",
    "df = df.dropna(subset = ['oil_volume'])\n",
    "\n",
    "print(\"Valores ausentes después de la eliminación:\")\n",
    "print(df.isna().sum())\n",
    "print()\n",
    "\n",
    "print(\"Columnas restantes:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57513e04",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.4 - Procesamiento de valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d79a55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "['BF6EA5AF' 'FB1E568E' 'EF15C7BA' '82F52E69' '4166D680' 'F4F5677'\n",
      " '386FE1ED' 'A5E0D927' 'E9E8A0CA' 'D3DD8D00' 'FD36A727' '8.18E+51'\n",
      " '2ABCF7B8' 'BDBE1D12' '508D6212']\n",
      "15\n",
      "\n",
      "['pop' 'ambient' 'dance' 'jazz' 'classicmetal' 'electronic' 'indie' nan]\n",
      "7\n",
      "\n",
      " user_id      15\n",
      "total play    14\n",
      "Artist        12\n",
      "genre          7\n",
      "track          9\n",
      "dtype: int64\n",
      "0\n",
      "    user_id  total play                                  Artist    genre  \\\n",
      "0  BF6EA5AF   92.851388                              Marina Rei      pop   \n",
      "1  FB1E568E  282.981000                            Stive Morgan  ambient   \n",
      "2  EF15C7BA    8.966000                                     NaN    dance   \n",
      "3  82F52E69  193.776327                                  Rixton      pop   \n",
      "4  4166D680    3.007000  Henry Hall & His Gleneagles Hotel Band     jazz   \n",
      "\n",
      "                    track  \n",
      "0                  Musica  \n",
      "1             Love Planet  \n",
      "2     Loving Every Minute  \n",
      "3  Me And My Broken Heart  \n",
      "4                    Home  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\Roberto Carlos\\\\source\\\\repos\\\\TripleTen_Data Science\\\\data_files\\\\music_log_raw.csv')\n",
    "\n",
    "print(df.duplicated().sum())\n",
    "print()\n",
    "\n",
    "print(df[' user_id'].unique())\n",
    "print(df[' user_id'].nunique())\n",
    "print()\n",
    "print(df['genre'].unique())\n",
    "print(df['genre'].nunique())\n",
    "print()\n",
    "print(df.nunique())\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop = True)\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rating = ['date', 'name', 'points']\n",
    "players = [\n",
    "        ['2018.01.01',  'Rafael Nadal', 10645],\n",
    "                ['2018.01.08',  'Rafael Nadal', 10600],\n",
    "                ['2018.01.29',  'Rafael Nadal', 9760],\n",
    "                ['2018.02.19',  'Roger Federer', 10105], \n",
    "                ['2018.03.05',  'Roger Federer', 10060],\n",
    "                ['2018.03.19',  'Roger Federerr', 9660],\n",
    "                ['2018.04.02',  'Rafael Nadal Parera', 8770],\n",
    "                ['2018.06.18',  'Roger Fedrer', 8920],\n",
    "                ['2018.06.25',  'Rafael Nadal Parera', 8770],\n",
    "                ['2018.07.16',  'Rafael Nadal Parera', 9310],\n",
    "                ['2018.08.13',  'Rafael Nadal Parera', 10220],\n",
    "                ['2018.08.20',  'Rafael Nadal Parera', 10040],\n",
    "                ['2018.09.10',  'Rafael Nadal Parera', 8760],\n",
    "                ['2018.10.08',  'Rafael Nadal Parera', 8260],\n",
    "                ['2018.10.15',  'Rafael Nadal Parera', 7660],\n",
    "                ['2018.11.05',  'Novak Djokovic', 8045],\n",
    "                ['2018.11.19',  'Novak Djokovic', 9045]\n",
    "]\n",
    "tennis = pd.DataFrame(data=players, columns=rating)\n",
    "print(tennis)\n",
    "print()\n",
    "print('-'*50)\n",
    "\n",
    "def replace_wrong_names(df, column, wrong_values, correct_value):\n",
    "    for wrong_value in wrong_values:\n",
    "        df[column] = df[column].replace(wrong_value, correct_value)\n",
    "    return df\n",
    "\n",
    "\n",
    "duplicates = ['Roger Federerr', 'Roger Fedrer']\n",
    "name = 'Roger Federer'\n",
    "tennis = replace_wrong_names(tennis,'name',duplicates, name)\n",
    "print(tennis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7167e7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hard'n'heavy\", 'hardcore', 'rancheras', 'hardstyle', 'hardtrance']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('E:\\\\datasets\\\\music_log_raw.csv')\n",
    "\n",
    "# Definir una función para corregir duplicados implícitos\n",
    "def corregir_duplicados_implicitos(df, columna, correcciones):\n",
    "    for key, value in correcciones.items():\n",
    "        df[columna] = df[columna].replace(key, value)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Diccionario con correcciones para la columna 'genre'\n",
    "correcciones_genre = {\n",
    "    \"hard-n-heavy\": \"hard'n'heavy\",\n",
    "    \"ranchera\": \"rancheras\"\n",
    "}\n",
    "\n",
    "# Aplicar la función para corregir los duplicados en la columna 'genre'\n",
    "df_corregido = corregir_duplicados_implicitos(df, 'genre', correcciones_genre)\n",
    "\n",
    "# Validación\n",
    "géneros_únicos = df['genre'].dropna().unique()\n",
    "filtros = [g for g in géneros_únicos if g.startswith('har') or g.startswith('ran')]\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(filtros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcae9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 1 y 2\n",
    "#Se necesita descargar steam-200k.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b1809",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.5 - Agrupación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8a2837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "acapella        1\n",
      "acid            2\n",
      "acoustic        2\n",
      "action          3\n",
      "adult          26\n",
      "               ..\n",
      "worldmusic      1\n",
      "wort            4\n",
      "yoga            3\n",
      "şiir            1\n",
      "электроника     2\n",
      "Name: genre, Length: 305, dtype: int64\n",
      "genre\n",
      "acapella        355.000000\n",
      "acid            484.922000\n",
      "acoustic        240.348163\n",
      "action          511.903586\n",
      "adult          2301.923250\n",
      "                  ...     \n",
      "worldmusic       20.000000\n",
      "wort            117.139871\n",
      "yoga            307.177143\n",
      "şiir              2.043000\n",
      "электроника       1.009000\n",
      "Name: total_play, Length: 305, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('E:\\\\datasets\\\\music_log_processed.csv')\n",
    "\n",
    "genre_groups = df.groupby('genre')['genre'].count()# escribe tu código aquí\n",
    "\n",
    "print(genre_groups)\n",
    "\n",
    "genre_groups = df.groupby('genre')['total_play'].sum()\n",
    "\n",
    "print(genre_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76712a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Number', 'Digimon', 'Stage', 'Type', 'Attribute', 'Memory',\n",
      "       'Equip Slots', 'Lv 50 HP', 'Lv50 SP', 'Lv50 Atk', 'Lv50 Def',\n",
      "       'Lv50 Int', 'Lv50 Spd'],\n",
      "      dtype='object')\n",
      "Distribución de los Digimons \n",
      " Stage\n",
      "Armor           3\n",
      "Baby            5\n",
      "Champion       54\n",
      "In-Training    11\n",
      "Mega           74\n",
      "Rookie         38\n",
      "Ultimate       58\n",
      "Ultra           6\n",
      "Name: Digimon, dtype: int64 \n",
      "\n",
      "Total de Salud \n",
      " Stage\n",
      "Armor            3510\n",
      "Baby             3640\n",
      "Champion        58700\n",
      "In-Training      9290\n",
      "Mega           107700\n",
      "Rookie          34980\n",
      "Ultimate        74640\n",
      "Ultra            9050\n",
      "Name: Lv 50 HP, dtype: int64 \n",
      "\n",
      "Promedio Nivel de Velocidad \n",
      " Stage\n",
      "Armor          128.666667\n",
      "Baby            77.000000\n",
      "Champion       103.259259\n",
      "In-Training     81.181818\n",
      "Mega           152.486486\n",
      "Rookie          90.236842\n",
      "Ultimate       122.586207\n",
      "Ultra          152.833333\n",
      "Name: Lv50 Spd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "digimon_data = pd.read_csv('E:\\\\datasets\\\\DigiDB_digimonlist.csv')\n",
    "\n",
    "print(digimon_data.columns)\n",
    "# Agrupar los datos\n",
    "grouped_stage_count =  digimon_data.groupby('Stage')['Digimon'].count()\n",
    "grouped_stage_sum =  digimon_data.groupby('Stage')['Lv 50 HP'].sum()\n",
    "\n",
    "grouped_spd_sum = digimon_data.groupby('Stage')['Lv50 Spd'].sum()\n",
    "grouped_spd_count = digimon_data.groupby('Stage')['Lv50 Spd'].count()\n",
    "grouped_stage_mean = grouped_spd_sum / grouped_spd_count\n",
    "\n",
    "# Mostrar los resultados\n",
    "print('Distribución de los Digimons', '\\n',grouped_stage_count,'\\n')\n",
    "print('Total de Salud', '\\n',grouped_stage_sum, '\\n',)\n",
    "print('Promedio Nivel de Velocidad', '\\n',grouped_stage_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421544f7",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 3.6 - Ordenar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c747f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  total_play                     artist        genre  \\\n",
      "52074  FFFD927C  125.330000                     Evoken        metal   \n",
      "48101  FFFC49ED   55.963000  Dj Nagual - Igor Borozdin        dance   \n",
      "9468   FFFAC306    0.000000             Fabio Borgazzi         jazz   \n",
      "57607  FFF8E0D3    3.553000                    no_info       ruspop   \n",
      "14726  FFF8D7EB    0.100000                 Quang Dung        world   \n",
      "11013  FFF67553  244.064000         Hentai Corporation         rock   \n",
      "22774  FFF4B04E  265.357000                       Noro          pop   \n",
      "21084  FFF380C1    1.000000          The East Pointers       celtic   \n",
      "58791  FFF2DD26    0.000000         Beware Of Darkness  alternative   \n",
      "52377  FFF1D41B   43.990204                  Grupo Sol        latin   \n",
      "\n",
      "                       track  \n",
      "52074   Of Purest Absolution  \n",
      "48101          Stars with us  \n",
      "9468         Samantha's Lips  \n",
      "57607      Я не могу сказать  \n",
      "14726      Dong Song Lo Dang  \n",
      "11013         Neurol Machine  \n",
      "22774                Mi Anun  \n",
      "21084   Queen Street Cobbler  \n",
      "58791         All Who Remain  \n",
      "52377  Happy Birthday To You  \n",
      "        user_id  total_play                   artist  genre  \\\n",
      "29939  ECE08CF4  691.957551                     Saor  metal   \n",
      "59913  D3174BD4  630.000000   The Flight Of Sleipnir  metal   \n",
      "16661  BDDAE2C0  589.183000  Suffocate for Fuck Sake  metal   \n",
      "37515  FEE3DC73  571.297959                  Somnuri  metal   \n",
      "49162  4015B412  540.682000                Norrsinnt  metal   \n",
      "27512  324A1234  537.521633       Scrambled Defuncts  metal   \n",
      "45211  528A6ECD  531.095000                    Lethe  metal   \n",
      "4546   358509C7  528.230000                   Magion  metal   \n",
      "35014  345DFD74  507.773000                  Malnatt  metal   \n",
      "8511   3F3D707F  498.000000            White Wizzard  metal   \n",
      "\n",
      "                                 track  \n",
      "29939                        Guardians  \n",
      "59913                           Awaken  \n",
      "16661                     33 Years Ago  \n",
      "37515                            Sheep  \n",
      "49162                        Skogsmakt  \n",
      "27512                      Retribution  \n",
      "45211  Therefore Let Us Feed the Beast  \n",
      "4546                   Lost in Reality  \n",
      "35014                  Ulver Nostalgia  \n",
      "8511                     Critical Mass  \n",
      "8895        no_info\n",
      "22764         world\n",
      "18217       ambient\n",
      "40854       ambient\n",
      "34922           new\n",
      "26143       ambient\n",
      "20208           new\n",
      "32905    avantgarde\n",
      "18183       ambient\n",
      "12455          jazz\n",
      "Name: genre, dtype: object\n",
      "genre\n",
      "dance          731069.475673\n",
      "pop            727425.542459\n",
      "electronic     679635.298107\n",
      "rock           630434.772021\n",
      "hiphop         297112.321237\n",
      "classical      271098.177081\n",
      "world          256630.643956\n",
      "jazz           213871.653640\n",
      "alternative    170130.211929\n",
      "metal          154435.488092\n",
      "Name: total_play, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('E:\\\\datasets\\\\music_log_processed.csv')\n",
    "\n",
    "df_ordenado = df.sort_values(by = 'user_id', ascending = False)\n",
    "\n",
    "print(df_ordenado.head(10))\n",
    "\n",
    "metal_ordenado = df[df['genre'] == 'metal']\n",
    "metal_ordenado = metal_ordenado.sort_values(by = 'total_play', ascending = False)\n",
    "#.sort_values(by = 'total_play', ascending = False)\n",
    "\n",
    "print(metal_ordenado.head(10))\n",
    "\n",
    "ordenado = df.sort_values(by = 'total_play', ascending = False)\n",
    "\n",
    "print(ordenado['genre'].head(10))\n",
    "\n",
    "time_by_genre = df.groupby('genre')['total_play'].sum()\n",
    "\n",
    "time_by_genre_sort = time_by_genre.sort_values(ascending = False)\n",
    "\n",
    "print(time_by_genre_sort.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7bff8",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 4.1 - Contar valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408597f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   user_id   200000 non-null  int64 \n",
      " 1   source    198326 non-null  object\n",
      " 2   email     13953 non-null   object\n",
      " 3   purchase  200000 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.1+ MB\n",
      "user_id          0\n",
      "source        1674\n",
      "email       186047\n",
      "purchase         0\n",
      "dtype: int64\n",
      "\n",
      "source\n",
      "other      133834\n",
      "context     52032\n",
      "email       12279\n",
      "NaN          1674\n",
      "undef         181\n",
      "Name: count, dtype: int64\n",
      "\n",
      "email\n",
      "410a2a3c23    9\n",
      "4526cc437a    9\n",
      "17c4fb26f9    8\n",
      "33f8a3d521    7\n",
      "5a4c033120    7\n",
      "             ..\n",
      "6d5069d25d    1\n",
      "9be4dcaf96    1\n",
      "e0ddbe4106    1\n",
      "d2f5ea92fa    1\n",
      "456e4d4d7c    1\n",
      "Name: count, Length: 6062, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('E:\\\\datasets\\\\visit_log.csv')\n",
    "\n",
    "df_logs.info()\n",
    "print(df_logs.isna().sum())\n",
    "print()\n",
    "print(df_logs['source'].value_counts(dropna = False))\n",
    "print()\n",
    "email_values = df_logs['email'].value_counts()\n",
    "print(email_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc364743",
   "metadata": {},
   "source": [
    "### Sprint 3: Capitulo 4.2 - Filtrar DataFrames por valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e28406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id   source       email  purchase\n",
      "0       7141786820    other         NaN         0\n",
      "1       5644686960    email  c129aa540a         0\n",
      "2       1914055396  context         NaN         0\n",
      "3       4099355752    other         NaN         0\n",
      "4       6032477554  context         NaN         1\n",
      "...            ...      ...         ...       ...\n",
      "199995  8714621942    other         NaN         0\n",
      "199996  6064948744  context         NaN         1\n",
      "199997  9210683879  context         NaN         0\n",
      "199998  1629959686    other         NaN         1\n",
      "199999  2089329795    other         NaN         0\n",
      "\n",
      "[198326 rows x 4 columns]\n",
      "           user_id source       email  purchase\n",
      "1       5644686960  email  c129aa540a         0\n",
      "11      8623045648  email  d6d19c571c         0\n",
      "18      5739438900  email  19379ee49c         0\n",
      "19      7486955288  email  09c27794fa         0\n",
      "33      7298923004  email  1fe184ed73         0\n",
      "...            ...    ...         ...       ...\n",
      "199922  4075894991  email  2c9a202435         0\n",
      "199958  9794381984  email  85712b433a         0\n",
      "199970  3396355438  email  4bba3fde78         0\n",
      "199979  5008169696  email  e5128e15fd         0\n",
      "199989  9470921783  email  3977de6aaa         0\n",
      "\n",
      "[12279 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('E:\\\\datasets\\\\visit_log.csv')\n",
    "\n",
    "print(df_logs[~df_logs['source'].isna()]) #~invierte los valores True a False y viceversa\n",
    "\n",
    "print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fea9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id source       email  purchase\n",
      "1   5644686960  email  c129aa540a         0\n",
      "11  8623045648  email  d6d19c571c         0\n",
      "18  5739438900  email  19379ee49c         0\n",
      "19  7486955288  email  09c27794fa         0\n",
      "22  1397217221    NaN  79ac569f0b         0\n",
      "33  7298923004  email  1fe184ed73         0\n",
      "43  6034222291  email  fb58a27f03         0\n",
      "49  5062457902    NaN  9ddce3a861         0\n",
      "56  5690036640  email  a088a48182         0\n",
      "66  9963049355  email  9cc43ebd15         0\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [user_id, source, email, purchase]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('E:\\\\datasets\\\\visit_log.csv')\n",
    "\n",
    "df_emails = df_logs[~df_logs['email'].isna()]\n",
    "\n",
    "print(df_emails.head(10))\n",
    "\n",
    "#Ejercicio 2\n",
    "print()\n",
    "\n",
    "df_emails = df_logs[(df_logs['email'].isna()) & (df_logs['source'].isna())]\n",
    "\n",
    "print(df_emails)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
